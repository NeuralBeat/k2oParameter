{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT DEPENDENCIES AND LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import knock_evaluator\n",
    "\n",
    "from knock_evaluator import mimic_knock_detection, find_knock_event_ended, calculate_ZImpactReturn, calculate_Very_High_Impact, calculate_DeployFlag, reshape_sequence, calculate_Has_It_Knocked\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, label):\n",
    "    \"\"\"\n",
    "    Process all files in the given folder and compile data into a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path: Path to the folder containing the files.\n",
    "    - label: The label to assign to all data from this folder (e.g., 1 for valid, 0 for invalid).\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame containing all processed data from the files.\n",
    "    \"\"\"\n",
    "    all_data = []  # List to hold data from all files\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Ensure we're only processing .csv files\n",
    "        if os.path.isfile(file_path) and file_path.endswith('.csv'):\n",
    "            # Read the file\n",
    "            data = pd.read_csv(file_path)\n",
    "            \n",
    "            # Filter rows for xBuffer, yBuffer, zBuffer and reset index\n",
    "            x_data = data[data['Expression'] == 'xBuffer'].reset_index(drop=True)\n",
    "            y_data = data[data['Expression'] == 'yBuffer'].reset_index(drop=True)\n",
    "            z_data = data[data['Expression'] == 'zBuffer'].reset_index(drop=True)\n",
    "            \n",
    "            # Ensure data is aligned\n",
    "            min_length = min(len(x_data), len(y_data), len(z_data))\n",
    "            structured_df = pd.DataFrame({\n",
    "                'x': x_data['Value'].head(min_length),\n",
    "                'y': y_data['Value'].head(min_length),\n",
    "                'z': z_data['Value'].head(min_length),\n",
    "                'label': label\n",
    "            })\n",
    "            \n",
    "            # Append to the list\n",
    "            all_data.append(structured_df)\n",
    "    \n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Expression</th>\n",
       "      <th>Value</th>\n",
       "      <th>Location</th>\n",
       "      <th>Refresh</th>\n",
       "      <th>Access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>extractionBuffer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x20005EDC</td>\n",
       "      <td>Off</td>\n",
       "      <td>private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x20005EDC</td>\n",
       "      <td>Off</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>xBuffer</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0x20005EDC</td>\n",
       "      <td>Off</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>yBuffer</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0x20005EDE</td>\n",
       "      <td>Off</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>zBuffer</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0x20005EE0</td>\n",
       "      <td>Off</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level        Expression  Value    Location Refresh   Access\n",
       "0      0  extractionBuffer    NaN  0x20005EDC     Off  private\n",
       "1      1               [0]    NaN  0x20005EDC     Off   public\n",
       "2      2           xBuffer    9.0  0x20005EDC     Off   public\n",
       "3      2           yBuffer  116.0  0x20005EDE     Off   public\n",
       "4      2           zBuffer   54.0  0x20005EE0     Off   public"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the valid knock data\n",
    "valid_data_path = 'data/valid/valid1.csv'\n",
    "valid_data = pd.read_csv(valid_data_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x      y     z  label\n",
       "0    9.0  116.0  54.0      1\n",
       "1    2.0  -20.0  99.0      1\n",
       "2  100.0  111.0 -22.0      1\n",
       "3   33.0   76.0  34.0      1\n",
       "4   15.0  -25.0 -24.0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extract only the rows that contain acceleration values and reset index to avoid grouping issues\n",
    "x_data = valid_data[valid_data['Expression'] == 'xBuffer'].reset_index(drop=True)\n",
    "y_data = valid_data[valid_data['Expression'] == 'yBuffer'].reset_index(drop=True)\n",
    "z_data = valid_data[valid_data['Expression'] == 'zBuffer'].reset_index(drop=True)\n",
    "\n",
    "# Ensure we only take as many rows as the shortest among x, y, z to keep data aligned\n",
    "min_length = min(len(x_data), len(y_data), len(z_data))\n",
    "\n",
    "# Reconstruct the DataFrame using the aligned data\n",
    "structured_df_aligned = pd.DataFrame({\n",
    "    'x': x_data['Value'].head(min_length),\n",
    "    'y': y_data['Value'].head(min_length),\n",
    "    'z': z_data['Value'].head(min_length),\n",
    "    'label': 1  # Label for valid knock\n",
    "})\n",
    "\n",
    "structured_df_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_sequences(df, label):\n",
    "    \"\"\"\n",
    "    Structures the DataFrame such that each 90-row sequence (representing 30 time points of x, y, z data)\n",
    "    is treated as a single observation.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the sequences.\n",
    "    - label: The label for these sequences (1 for valid, 0 for invalid).\n",
    "    \n",
    "    Returns:\n",
    "    - A list of tuples, where each tuple is (sequence, label), and\n",
    "      each sequence is a (90, ) shape array if flattening or a (30, 3) array if keeping x, y, z separate.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    num_sequences = len(df) // 90  # Assuming each sequence is exactly 90 rows\n",
    "    \n",
    "    for i in range(num_sequences):\n",
    "        start_idx = i * 90\n",
    "        sequence = df.iloc[start_idx:start_idx + 90][['x', 'y', 'z']].values.flatten()  # Flattened sequence\n",
    "        # Alternatively, keep as a (30, 3) array for models that can handle sequence data\n",
    "        # sequence = df.iloc[start_idx:start_idx + 90][['x', 'y', 'z']].values.reshape((30, 3))\n",
    "        sequences.append((sequence, label))\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all valid / invalid data into data frames, Label & Combine them to Sequences. Afterwards Combine them to global Sequence structure and Shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_valid = 'data/valid'  \n",
    "folder_path_invalid = 'data/invalid'  \n",
    "valid_data = process_folder(folder_path_valid, label=1)\n",
    "invalid_data = process_folder(folder_path_invalid, label=0)\n",
    "\n",
    "# Assuming valid_data and invalid_data are already loaded and structured with one file per sequence\n",
    "valid_sequences = structure_sequences(valid_data, 1)\n",
    "invalid_sequences = structure_sequences(invalid_data, 0)\n",
    "\n",
    "all_sequences = valid_sequences + invalid_sequences\n",
    "random.shuffle(all_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels for model training\n",
    "X = np.array([seq[0] for seq in all_sequences])\n",
    "y = np.array([seq[1] for seq in all_sequences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - Test Split of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df = reshape_sequence(all_sequences[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prebuffer_size = 8\n",
    "knock_event_length_avg = 45\n",
    "knock_event_ended = prebuffer_size + knock_event_length_avg\n",
    "knock_algo_AngleXLatched = 8\n",
    "knock_algo_Vel_Zlatched = 9000\n",
    "knock_algo_Vel_Zlatched_Counter = 20\n",
    "knock_algo_HFA_Zlatched = 3200\n",
    "knock_algo_HFA_Zlatched_Counter = 15\n",
    "ZImpactReturn = False\n",
    "Very_High_Impact = False\n",
    "DeployFlag = False\n",
    "\n",
    "Has_It_Knocked = False\n",
    "\n",
    "very_high_counter = 5\n",
    "Acc_Latched_Counter = 25\n",
    "Acc_Latched_Threshold = 8500\n",
    "Vel_Latched_Counter = 30\n",
    "Vel_Latched_Threshold = 9000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the velocities as cumulative sum (integration) of each buffer\n",
    "sequence_df['xBuffer_quasi_velocity'] = np.cumsum(sequence_df['xBuffer'])\n",
    "sequence_df['yBuffer_quasi_velocity'] = np.cumsum(sequence_df['yBuffer'])\n",
    "sequence_df['zBuffer_quasi_velocity'] = np.cumsum(sequence_df['zBuffer'])\n",
    "\n",
    "# Calculate the energies of each buffer\n",
    "sequence_df['xBuffer_quasi_energy'] = (sequence_df['xBuffer_quasi_velocity'])**2\n",
    "sequence_df['yBuffer_quasi_energy'] = (sequence_df['yBuffer_quasi_velocity'])**2\n",
    "sequence_df['zBuffer_quasi_energy'] = (sequence_df['zBuffer_quasi_velocity'])**2\n",
    "\n",
    "sequence_df['xBuffer_quasi_work'] = np.cumsum(np.abs(sequence_df['xBuffer_quasi_velocity']))\n",
    "sequence_df['yBuffer_quasi_work'] = np.cumsum(np.abs(sequence_df['yBuffer_quasi_velocity']))\n",
    "sequence_df['zBuffer_quasi_work'] = np.cumsum(np.abs(sequence_df['zBuffer_quasi_velocity']))\n",
    "\n",
    "knock_event_ended_dynamic = find_knock_event_ended(sequence_df['zBuffer'], knock_algo_HFA_Zlatched, knock_algo_HFA_Zlatched_Counter, prebuffer_size)\n",
    "\n",
    "# Nulling values after the knock_event_ended parameter by setting them to 0\n",
    "# Update based on the dynamically determined knock_event_ended value\n",
    "if knock_event_ended_dynamic is not None and knock_event_ended_dynamic != 0:\n",
    "    knock_event_ended = knock_event_ended_dynamic\n",
    "    sequence_df.loc[knock_event_ended_dynamic+1:, 'xBuffer_quasi_velocity'] = 0\n",
    "    sequence_df.loc[knock_event_ended_dynamic+1:, 'yBuffer_quasi_velocity'] = 0\n",
    "    sequence_df.loc[knock_event_ended_dynamic+1:, 'zBuffer_quasi_velocity'] = 0\n",
    "    sequence_df.loc[knock_event_ended_dynamic+1:, 'xBuffer_quasi_energy'] = 0\n",
    "    sequence_df.loc[knock_event_ended_dynamic+1:, 'yBuffer_quasi_energy'] = 0\n",
    "    sequence_df.loc[knock_event_ended_dynamic+1:, 'zBuffer_quasi_energy'] = 0\n",
    "    sequence_df.loc[knock_event_ended_dynamic+1:, 'xBuffer_quasi_work'] = 0\n",
    "    sequence_df.loc[knock_event_ended_dynamic+1:, 'yBuffer_quasi_work'] = 0\n",
    "    sequence_df.loc[knock_event_ended_dynamic+1:, 'zBuffer_quasi_work'] = 0\n",
    "\n",
    "else:\n",
    "    sequence_df.loc[knock_event_ended+1:, 'xBuffer_quasi_velocity'] = 0\n",
    "    sequence_df.loc[knock_event_ended+1:, 'yBuffer_quasi_velocity'] = 0\n",
    "    sequence_df.loc[knock_event_ended+1:, 'zBuffer_quasi_velocity'] = 0\n",
    "    sequence_df.loc[knock_event_ended+1:, 'xBuffer_quasi_energy'] = 0\n",
    "    sequence_df.loc[knock_event_ended+1:, 'yBuffer_quasi_energy'] = 0\n",
    "    sequence_df.loc[knock_event_ended+1:, 'zBuffer_quasi_energy'] = 0\n",
    "    sequence_df.loc[knock_event_ended+1:, 'xBuffer_quasi_work'] = 0\n",
    "    sequence_df.loc[knock_event_ended+1:, 'yBuffer_quasi_work'] = 0\n",
    "    sequence_df.loc[knock_event_ended+1:, 'zBuffer_quasi_work'] = 0\n",
    "\n",
    "\n",
    "#Calculate several keay values\n",
    "maxZ_Acc = np.abs(sequence_df['zBuffer']).max()\n",
    "maxX_Vel = np.abs(sequence_df['xBuffer_quasi_velocity']).max()\n",
    "maxY_Vel = np.abs(sequence_df['yBuffer_quasi_velocity']).max()\n",
    "maxZ_Vel = np.abs(sequence_df['zBuffer_quasi_velocity']).max()\n",
    "minZ_Vel = sequence_df['zBuffer_quasi_velocity'].min()\n",
    "divXZ = maxZ_Vel/maxX_Vel\n",
    "divYZ = maxZ_Vel/maxY_Vel\n",
    "\n",
    "ZImpactReturn = calculate_ZImpactReturn(maxZ_Vel, maxX_Vel, maxY_Vel, minZ_Vel, knock_algo_AngleXLatched)\n",
    "Very_High_Impact = calculate_Very_High_Impact(sequence_df['zBuffer'], sequence_df['zBuffer_quasi_velocity'], very_high_counter)\n",
    "DeployFlag = calculate_DeployFlag(sequence_df['zBuffer'], sequence_df['zBuffer_quasi_velocity'], prebuffer_size, knock_event_ended, Acc_Latched_Counter, Vel_Latched_Counter, Acc_Latched_Threshold, Vel_Latched_Threshold)\n",
    "Has_It_Knocked = calculate_Has_It_Knocked(DeployFlag[0], Very_High_Impact, ZImpactReturn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(Has_It_Knocked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Label: 0, Detection Result: False\n"
     ]
    }
   ],
   "source": [
    "# Example parameters - replace with actual parameter values as needed\n",
    "params = {\n",
    "    'KLOPFALGO_HfaLatchedCounterThr_u8': 25,\n",
    "    'KLOPFALGO_VelLatchedCounterThr_u8': 30,\n",
    "    'KLOPFALGO_VelVeryHighCounterThr_u8': 5,\n",
    "    'KLOPFALGO_HfaThrZLatched_s16': 8500, \n",
    "    'KLOPFALGO_VelThrZLatched_s32': 9000,\n",
    "    'KLOPFALGO_WinkelThrXLatched_s16': 8\n",
    "    # Add other parameters as needed\n",
    "}\n",
    "# Test with the first sequence as an example\n",
    "sequence, label = all_sequences[0]\n",
    "result = mimic_knock_detection(sequence, params)\n",
    "\n",
    "print(f\"Sequence Label: {label}, Detection Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8504672897196262\n"
     ]
    }
   ],
   "source": [
    "predictions = [mimic_knock_detection(seq, params) for seq, _ in all_sequences]\n",
    "true_labels = [label for _, label in all_sequences]\n",
    "\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5  # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score across 5 folds: 0.8475101418497646\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(all_sequences):  # Use all_sequences directly\n",
    "    # Splitting data into training and test sets for this fold using list comprehension\n",
    "    train = [all_sequences[i] for i in train_index]\n",
    "    test = [all_sequences[i] for i in test_index]\n",
    "    \n",
    "    # Generate predictions for each sequence in the test set\n",
    "    predictions = [mimic_knock_detection(sequence, params) for sequence, _ in test]\n",
    "    \n",
    "    # Extract true labels for the test set\n",
    "    true_labels = [label for _, label in test]\n",
    "    \n",
    "    # Calculate F1 score and append to list\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate average F1 score across all folds\n",
    "average_f1 = np.mean(f1_scores)\n",
    "print(f\"Average F1 Score across {k} folds: {average_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETER OPTIMIZATION - STRATEGY: GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Score: 0.8857109891543178\n",
      "Best Parameters: {'KLOPFALGO_HfaLatchedCounterThr_u8': 15, 'KLOPFALGO_VelLatchedCounterThr_u8': 10, 'KLOPFALGO_VelVeryHighCounterThr_u8': 3, 'KLOPFALGO_HfaThrZLatched_s16': 7500, 'KLOPFALGO_VelThrZLatched_s32': 8000, 'KLOPFALGO_WinkelThrXLatched_s16': 6}\n"
     ]
    }
   ],
   "source": [
    "#Define parameter grid\n",
    "parameter_grid = {\n",
    "    'KLOPFALGO_HfaLatchedCounterThr_u8': [10, 15, 20, 25],\n",
    "    'KLOPFALGO_VelLatchedCounterThr_u8': [10, 20, 30, 40],\n",
    "    'KLOPFALGO_VelVeryHighCounterThr_u8': [3,5,8],\n",
    "    'KLOPFALGO_HfaThrZLatched_s16': [6500, 7500, 8500, 9500], \n",
    "    'KLOPFALGO_VelThrZLatched_s32': [6000, 7000, 8000, 9000, 10000],\n",
    "    'KLOPFALGO_WinkelThrXLatched_s16': [4,6,8,10]\n",
    "    # Add other parameters as needed\n",
    "}\n",
    "# Generate all combinations of parameters\n",
    "param_combinations = list(itertools.product(*(parameter_grid[param_name] for param_name in parameter_grid)))\n",
    "\n",
    "# Placeholder for best score and corresponding parameters\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for combination in param_combinations:\n",
    "    params = dict(zip(parameter_grid.keys(), combination))\n",
    "    \n",
    "    # List to hold F1 scores for each fold\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(all_sequences):\n",
    "        train, test = [all_sequences[i] for i in train_index], [all_sequences[i] for i in test_index]\n",
    "        predictions = [mimic_knock_detection(sequence, params) for sequence, _ in test]\n",
    "        true_labels = [label for _, label in test]\n",
    "        f1 = f1_score(true_labels, predictions)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # Calculate average F1 score for this parameter combination\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    if avg_f1 > best_score:\n",
    "        best_score = avg_f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best F1 Score:\", best_score)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETER OPTIMIZATION - STRATEGY: BAYESIAN OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | KLOPFA... | KLOPFA... | KLOPFA... | KLOPFA... | KLOPFA... | KLOPFA... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8652   \u001b[0m | \u001b[0m16.26    \u001b[0m | \u001b[0m8.881e+03\u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m7.209e+03\u001b[0m | \u001b[0m3.734    \u001b[0m | \u001b[0m4.739    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.8007   \u001b[0m | \u001b[0m12.79    \u001b[0m | \u001b[0m7.382e+03\u001b[0m | \u001b[0m21.9     \u001b[0m | \u001b[0m8.155e+03\u001b[0m | \u001b[0m5.096    \u001b[0m | \u001b[0m9.482    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.8703   \u001b[0m | \u001b[95m13.07    \u001b[0m | \u001b[95m9.512e+03\u001b[0m | \u001b[95m10.82    \u001b[0m | \u001b[95m8.682e+03\u001b[0m | \u001b[95m5.087    \u001b[0m | \u001b[95m8.47     \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.788    \u001b[0m | \u001b[0m12.11    \u001b[0m | \u001b[0m6.792e+03\u001b[0m | \u001b[0m34.02    \u001b[0m | \u001b[0m9.873e+03\u001b[0m | \u001b[0m4.567    \u001b[0m | \u001b[0m9.539    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.8162   \u001b[0m | \u001b[0m23.15    \u001b[0m | \u001b[0m9.578e+03\u001b[0m | \u001b[0m12.55    \u001b[0m | \u001b[0m6.156e+03\u001b[0m | \u001b[0m3.849    \u001b[0m | \u001b[0m11.03    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.825    \u001b[0m | \u001b[0m11.48    \u001b[0m | \u001b[0m7.684e+03\u001b[0m | \u001b[0m38.74    \u001b[0m | \u001b[0m8.133e+03\u001b[0m | \u001b[0m6.459    \u001b[0m | \u001b[0m6.524    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.83     \u001b[0m | \u001b[0m20.3     \u001b[0m | \u001b[0m9.339e+03\u001b[0m | \u001b[0m10.55    \u001b[0m | \u001b[0m9.001e+03\u001b[0m | \u001b[0m7.944    \u001b[0m | \u001b[0m9.985    \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.8815   \u001b[0m | \u001b[95m14.21    \u001b[0m | \u001b[95m9.157e+03\u001b[0m | \u001b[95m13.1     \u001b[0m | \u001b[95m7.792e+03\u001b[0m | \u001b[95m7.543    \u001b[0m | \u001b[95m6.349    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.8489   \u001b[0m | \u001b[0m14.32    \u001b[0m | \u001b[0m6.52e+03 \u001b[0m | \u001b[0m10.58    \u001b[0m | \u001b[0m8.715e+03\u001b[0m | \u001b[0m4.058    \u001b[0m | \u001b[0m6.124    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8369   \u001b[0m | \u001b[0m17.37    \u001b[0m | \u001b[0m6.213e+03\u001b[0m | \u001b[0m27.22    \u001b[0m | \u001b[0m6.587e+03\u001b[0m | \u001b[0m5.947    \u001b[0m | \u001b[0m9.598    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.8464   \u001b[0m | \u001b[0m21.73    \u001b[0m | \u001b[0m9.438e+03\u001b[0m | \u001b[0m12.8     \u001b[0m | \u001b[0m8.184e+03\u001b[0m | \u001b[0m5.314    \u001b[0m | \u001b[0m8.109    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.8744   \u001b[0m | \u001b[0m13.69    \u001b[0m | \u001b[0m9.163e+03\u001b[0m | \u001b[0m35.28    \u001b[0m | \u001b[0m7.786e+03\u001b[0m | \u001b[0m7.182    \u001b[0m | \u001b[0m6.49     \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.8302   \u001b[0m | \u001b[0m10.73    \u001b[0m | \u001b[0m9.12e+03 \u001b[0m | \u001b[0m14.5     \u001b[0m | \u001b[0m7.916e+03\u001b[0m | \u001b[0m7.401    \u001b[0m | \u001b[0m8.441    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8538   \u001b[0m | \u001b[0m11.07    \u001b[0m | \u001b[0m9.163e+03\u001b[0m | \u001b[0m24.91    \u001b[0m | \u001b[0m7.779e+03\u001b[0m | \u001b[0m4.125    \u001b[0m | \u001b[0m6.868    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.8215   \u001b[0m | \u001b[0m20.6     \u001b[0m | \u001b[0m9.146e+03\u001b[0m | \u001b[0m18.73    \u001b[0m | \u001b[0m7.804e+03\u001b[0m | \u001b[0m5.285    \u001b[0m | \u001b[0m10.58    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.8558   \u001b[0m | \u001b[0m11.06    \u001b[0m | \u001b[0m9.17e+03 \u001b[0m | \u001b[0m34.61    \u001b[0m | \u001b[0m7.785e+03\u001b[0m | \u001b[0m3.757    \u001b[0m | \u001b[0m7.968    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.8341   \u001b[0m | \u001b[0m21.63    \u001b[0m | \u001b[0m9.17e+03 \u001b[0m | \u001b[0m36.66    \u001b[0m | \u001b[0m7.793e+03\u001b[0m | \u001b[0m4.686    \u001b[0m | \u001b[0m9.198    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.8569   \u001b[0m | \u001b[0m19.61    \u001b[0m | \u001b[0m9.162e+03\u001b[0m | \u001b[0m12.03    \u001b[0m | \u001b[0m7.803e+03\u001b[0m | \u001b[0m5.663    \u001b[0m | \u001b[0m8.778    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.8127   \u001b[0m | \u001b[0m13.98    \u001b[0m | \u001b[0m6.524e+03\u001b[0m | \u001b[0m16.85    \u001b[0m | \u001b[0m8.719e+03\u001b[0m | \u001b[0m3.852    \u001b[0m | \u001b[0m9.924    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.8583   \u001b[0m | \u001b[0m23.47    \u001b[0m | \u001b[0m6.346e+03\u001b[0m | \u001b[0m26.79    \u001b[0m | \u001b[0m7.019e+03\u001b[0m | \u001b[0m6.778    \u001b[0m | \u001b[0m5.902    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.8224   \u001b[0m | \u001b[0m21.34    \u001b[0m | \u001b[0m8.894e+03\u001b[0m | \u001b[0m20.99    \u001b[0m | \u001b[0m7.216e+03\u001b[0m | \u001b[0m3.597    \u001b[0m | \u001b[0m11.52    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.8224   \u001b[0m | \u001b[0m21.5     \u001b[0m | \u001b[0m9.165e+03\u001b[0m | \u001b[0m15.25    \u001b[0m | \u001b[0m7.793e+03\u001b[0m | \u001b[0m3.955    \u001b[0m | \u001b[0m11.23    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m21.32    \u001b[0m | \u001b[0m9.526e+03\u001b[0m | \u001b[0m17.6     \u001b[0m | \u001b[0m8.684e+03\u001b[0m | \u001b[0m7.172    \u001b[0m | \u001b[0m4.532    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m12.44    \u001b[0m | \u001b[0m9.506e+03\u001b[0m | \u001b[0m15.78    \u001b[0m | \u001b[0m8.686e+03\u001b[0m | \u001b[0m7.983    \u001b[0m | \u001b[0m10.17    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.8475   \u001b[0m | \u001b[0m18.4     \u001b[0m | \u001b[0m8.358e+03\u001b[0m | \u001b[0m31.74    \u001b[0m | \u001b[0m9.034e+03\u001b[0m | \u001b[0m5.183    \u001b[0m | \u001b[0m9.283    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.8389   \u001b[0m | \u001b[0m15.77    \u001b[0m | \u001b[0m8.356e+03\u001b[0m | \u001b[0m29.67    \u001b[0m | \u001b[0m9.038e+03\u001b[0m | \u001b[0m3.584    \u001b[0m | \u001b[0m10.85    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.847    \u001b[0m | \u001b[0m24.14    \u001b[0m | \u001b[0m6.351e+03\u001b[0m | \u001b[0m11.37    \u001b[0m | \u001b[0m7.039e+03\u001b[0m | \u001b[0m7.081    \u001b[0m | \u001b[0m4.481    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.8744   \u001b[0m | \u001b[0m17.43    \u001b[0m | \u001b[0m6.513e+03\u001b[0m | \u001b[0m11.59    \u001b[0m | \u001b[0m8.711e+03\u001b[0m | \u001b[0m3.718    \u001b[0m | \u001b[0m6.846    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.8224   \u001b[0m | \u001b[0m19.69    \u001b[0m | \u001b[0m9.182e+03\u001b[0m | \u001b[0m29.52    \u001b[0m | \u001b[0m7.769e+03\u001b[0m | \u001b[0m3.688    \u001b[0m | \u001b[0m11.27    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.8698   \u001b[0m | \u001b[0m16.08    \u001b[0m | \u001b[0m8.932e+03\u001b[0m | \u001b[0m35.7     \u001b[0m | \u001b[0m9.963e+03\u001b[0m | \u001b[0m7.273    \u001b[0m | \u001b[0m5.998    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.8514   \u001b[0m | \u001b[0m15.53    \u001b[0m | \u001b[0m9.51e+03 \u001b[0m | \u001b[0m16.41    \u001b[0m | \u001b[0m8.677e+03\u001b[0m | \u001b[0m4.884    \u001b[0m | \u001b[0m9.37     \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.8202   \u001b[0m | \u001b[0m15.55    \u001b[0m | \u001b[0m8.877e+03\u001b[0m | \u001b[0m11.11    \u001b[0m | \u001b[0m7.199e+03\u001b[0m | \u001b[0m4.134    \u001b[0m | \u001b[0m11.59    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.8637   \u001b[0m | \u001b[0m17.54    \u001b[0m | \u001b[0m6.354e+03\u001b[0m | \u001b[0m10.12    \u001b[0m | \u001b[0m7.042e+03\u001b[0m | \u001b[0m7.869    \u001b[0m | \u001b[0m6.341    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.8622   \u001b[0m | \u001b[0m15.68    \u001b[0m | \u001b[0m6.331e+03\u001b[0m | \u001b[0m25.22    \u001b[0m | \u001b[0m7.698e+03\u001b[0m | \u001b[0m3.145    \u001b[0m | \u001b[0m5.248    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.8717   \u001b[0m | \u001b[0m20.57    \u001b[0m | \u001b[0m6.535e+03\u001b[0m | \u001b[0m33.94    \u001b[0m | \u001b[0m8.545e+03\u001b[0m | \u001b[0m6.086    \u001b[0m | \u001b[0m8.268    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.8209   \u001b[0m | \u001b[0m22.3     \u001b[0m | \u001b[0m9.425e+03\u001b[0m | \u001b[0m22.41    \u001b[0m | \u001b[0m9.268e+03\u001b[0m | \u001b[0m7.977    \u001b[0m | \u001b[0m9.578    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.8709   \u001b[0m | \u001b[0m17.09    \u001b[0m | \u001b[0m8.927e+03\u001b[0m | \u001b[0m33.86    \u001b[0m | \u001b[0m9.966e+03\u001b[0m | \u001b[0m3.554    \u001b[0m | \u001b[0m6.003    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.8744   \u001b[0m | \u001b[0m17.28    \u001b[0m | \u001b[0m6.518e+03\u001b[0m | \u001b[0m13.59    \u001b[0m | \u001b[0m8.701e+03\u001b[0m | \u001b[0m3.968    \u001b[0m | \u001b[0m6.83     \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.8495   \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m9.149e+03\u001b[0m | \u001b[0m18.38    \u001b[0m | \u001b[0m7.798e+03\u001b[0m | \u001b[0m4.816    \u001b[0m | \u001b[0m8.156    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.8717   \u001b[0m | \u001b[0m14.78    \u001b[0m | \u001b[0m9.165e+03\u001b[0m | \u001b[0m30.51    \u001b[0m | \u001b[0m7.78e+03 \u001b[0m | \u001b[0m6.144    \u001b[0m | \u001b[0m8.708    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.8717   \u001b[0m | \u001b[0m21.67    \u001b[0m | \u001b[0m6.529e+03\u001b[0m | \u001b[0m24.54    \u001b[0m | \u001b[0m8.548e+03\u001b[0m | \u001b[0m5.566    \u001b[0m | \u001b[0m8.611    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.8703   \u001b[0m | \u001b[0m17.22    \u001b[0m | \u001b[0m6.511e+03\u001b[0m | \u001b[0m18.8     \u001b[0m | \u001b[0m8.71e+03 \u001b[0m | \u001b[0m7.213    \u001b[0m | \u001b[0m5.587    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.7408   \u001b[0m | \u001b[0m10.76    \u001b[0m | \u001b[0m6.343e+03\u001b[0m | \u001b[0m27.34    \u001b[0m | \u001b[0m7.033e+03\u001b[0m | \u001b[0m7.513    \u001b[0m | \u001b[0m8.241    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.801    \u001b[0m | \u001b[0m12.44    \u001b[0m | \u001b[0m6.528e+03\u001b[0m | \u001b[0m24.62    \u001b[0m | \u001b[0m8.554e+03\u001b[0m | \u001b[0m3.109    \u001b[0m | \u001b[0m8.027    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.8475   \u001b[0m | \u001b[0m19.54    \u001b[0m | \u001b[0m8.352e+03\u001b[0m | \u001b[0m34.95    \u001b[0m | \u001b[0m9.035e+03\u001b[0m | \u001b[0m7.421    \u001b[0m | \u001b[0m9.313    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.8744   \u001b[0m | \u001b[0m15.82    \u001b[0m | \u001b[0m9.503e+03\u001b[0m | \u001b[0m17.31    \u001b[0m | \u001b[0m8.677e+03\u001b[0m | \u001b[0m4.769    \u001b[0m | \u001b[0m6.011    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.8269   \u001b[0m | \u001b[0m19.63    \u001b[0m | \u001b[0m8.924e+03\u001b[0m | \u001b[0m24.58    \u001b[0m | \u001b[0m9.967e+03\u001b[0m | \u001b[0m6.201    \u001b[0m | \u001b[0m10.89    \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.8564   \u001b[0m | \u001b[0m22.63    \u001b[0m | \u001b[0m9.504e+03\u001b[0m | \u001b[0m16.75    \u001b[0m | \u001b[0m8.661e+03\u001b[0m | \u001b[0m3.892    \u001b[0m | \u001b[0m7.635    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.8338   \u001b[0m | \u001b[0m15.87    \u001b[0m | \u001b[0m6.514e+03\u001b[0m | \u001b[0m14.79    \u001b[0m | \u001b[0m8.702e+03\u001b[0m | \u001b[0m4.974    \u001b[0m | \u001b[0m9.764    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.8087   \u001b[0m | \u001b[0m24.89    \u001b[0m | \u001b[0m7.142e+03\u001b[0m | \u001b[0m12.75    \u001b[0m | \u001b[0m8.926e+03\u001b[0m | \u001b[0m7.473    \u001b[0m | \u001b[0m11.15    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.8272   \u001b[0m | \u001b[0m11.64    \u001b[0m | \u001b[0m8.926e+03\u001b[0m | \u001b[0m39.99    \u001b[0m | \u001b[0m9.966e+03\u001b[0m | \u001b[0m7.606    \u001b[0m | \u001b[0m9.241    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.8162   \u001b[0m | \u001b[0m23.64    \u001b[0m | \u001b[0m8.305e+03\u001b[0m | \u001b[0m11.06    \u001b[0m | \u001b[0m6.162e+03\u001b[0m | \u001b[0m7.663    \u001b[0m | \u001b[0m11.64    \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.8265   \u001b[0m | \u001b[0m16.39    \u001b[0m | \u001b[0m7.908e+03\u001b[0m | \u001b[0m29.74    \u001b[0m | \u001b[0m9.449e+03\u001b[0m | \u001b[0m3.697    \u001b[0m | \u001b[0m11.16    \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.8707   \u001b[0m | \u001b[0m15.79    \u001b[0m | \u001b[0m9.617e+03\u001b[0m | \u001b[0m33.77    \u001b[0m | \u001b[0m8.787e+03\u001b[0m | \u001b[0m5.193    \u001b[0m | \u001b[0m7.626    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.8386   \u001b[0m | \u001b[0m23.99    \u001b[0m | \u001b[0m9.108e+03\u001b[0m | \u001b[0m22.01    \u001b[0m | \u001b[0m6.059e+03\u001b[0m | \u001b[0m5.52     \u001b[0m | \u001b[0m5.992    \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.8663   \u001b[0m | \u001b[0m15.82    \u001b[0m | \u001b[0m6.036e+03\u001b[0m | \u001b[0m32.58    \u001b[0m | \u001b[0m6.854e+03\u001b[0m | \u001b[0m7.682    \u001b[0m | \u001b[0m6.28     \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.8521   \u001b[0m | \u001b[0m11.2     \u001b[0m | \u001b[0m9.418e+03\u001b[0m | \u001b[0m17.02    \u001b[0m | \u001b[0m7.08e+03 \u001b[0m | \u001b[0m6.339    \u001b[0m | \u001b[0m7.84     \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m0.8364   \u001b[0m | \u001b[0m12.63    \u001b[0m | \u001b[0m7.871e+03\u001b[0m | \u001b[0m24.29    \u001b[0m | \u001b[0m6.09e+03 \u001b[0m | \u001b[0m5.502    \u001b[0m | \u001b[0m5.774    \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.8555   \u001b[0m | \u001b[0m14.02    \u001b[0m | \u001b[0m8.931e+03\u001b[0m | \u001b[0m26.0     \u001b[0m | \u001b[0m9.958e+03\u001b[0m | \u001b[0m6.799    \u001b[0m | \u001b[0m9.306    \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.8282   \u001b[0m | \u001b[0m13.19    \u001b[0m | \u001b[0m6.332e+03\u001b[0m | \u001b[0m24.74    \u001b[0m | \u001b[0m7.707e+03\u001b[0m | \u001b[0m3.102    \u001b[0m | \u001b[0m7.088    \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m0.8495   \u001b[0m | \u001b[0m16.76    \u001b[0m | \u001b[0m8.563e+03\u001b[0m | \u001b[0m31.65    \u001b[0m | \u001b[0m6.621e+03\u001b[0m | \u001b[0m3.944    \u001b[0m | \u001b[0m9.448    \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m0.7891   \u001b[0m | \u001b[0m13.24    \u001b[0m | \u001b[0m6.593e+03\u001b[0m | \u001b[0m32.03    \u001b[0m | \u001b[0m7.623e+03\u001b[0m | \u001b[0m3.116    \u001b[0m | \u001b[0m11.54    \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m0.8421   \u001b[0m | \u001b[0m23.14    \u001b[0m | \u001b[0m7.76e+03 \u001b[0m | \u001b[0m26.98    \u001b[0m | \u001b[0m9.507e+03\u001b[0m | \u001b[0m4.344    \u001b[0m | \u001b[0m9.267    \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m0.7603   \u001b[0m | \u001b[0m10.31    \u001b[0m | \u001b[0m7.527e+03\u001b[0m | \u001b[0m17.12    \u001b[0m | \u001b[0m9.317e+03\u001b[0m | \u001b[0m3.725    \u001b[0m | \u001b[0m10.2     \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m0.8363   \u001b[0m | \u001b[0m13.9     \u001b[0m | \u001b[0m8.716e+03\u001b[0m | \u001b[0m38.35    \u001b[0m | \u001b[0m9.98e+03 \u001b[0m | \u001b[0m3.577    \u001b[0m | \u001b[0m9.078    \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m0.8187   \u001b[0m | \u001b[0m11.26    \u001b[0m | \u001b[0m7.57e+03 \u001b[0m | \u001b[0m29.17    \u001b[0m | \u001b[0m8.688e+03\u001b[0m | \u001b[0m3.127    \u001b[0m | \u001b[0m8.0      \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m0.8364   \u001b[0m | \u001b[0m24.4     \u001b[0m | \u001b[0m8.355e+03\u001b[0m | \u001b[0m39.1     \u001b[0m | \u001b[0m9.025e+03\u001b[0m | \u001b[0m6.278    \u001b[0m | \u001b[0m8.335    \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m0.834    \u001b[0m | \u001b[0m13.26    \u001b[0m | \u001b[0m6.03e+03 \u001b[0m | \u001b[0m32.22    \u001b[0m | \u001b[0m6.862e+03\u001b[0m | \u001b[0m4.88     \u001b[0m | \u001b[0m5.582    \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m0.8332   \u001b[0m | \u001b[0m12.97    \u001b[0m | \u001b[0m7.425e+03\u001b[0m | \u001b[0m13.42    \u001b[0m | \u001b[0m8.183e+03\u001b[0m | \u001b[0m7.787    \u001b[0m | \u001b[0m7.74     \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m0.8669   \u001b[0m | \u001b[0m13.24    \u001b[0m | \u001b[0m9.803e+03\u001b[0m | \u001b[0m28.28    \u001b[0m | \u001b[0m9.729e+03\u001b[0m | \u001b[0m3.83     \u001b[0m | \u001b[0m4.525    \u001b[0m |\n",
      "=================================================================================================\n",
      "Best F1 Score: 0.8814685649118935\n",
      "Best Parameters: {'KLOPFALGO_HfaLatchedCounterThr_u8': 14.206659880966079, 'KLOPFALGO_HfaThrZLatched_s16': 9157.117313805953, 'KLOPFALGO_VelLatchedCounterThr_u8': 13.096780197329261, 'KLOPFALGO_VelThrZLatched_s32': 7791.574104703621, 'KLOPFALGO_VelVeryHighCounterThr_u8': 7.542977515465478, 'KLOPFALGO_WinkelThrXLatched_s16': 6.348913186989436}\n"
     ]
    }
   ],
   "source": [
    "def knock_detection_cv(KLOPFALGO_HfaLatchedCounterThr_u8, KLOPFALGO_VelLatchedCounterThr_u8, KLOPFALGO_VelVeryHighCounterThr_u8, KLOPFALGO_HfaThrZLatched_s16, KLOPFALGO_VelThrZLatched_s32, KLOPFALGO_WinkelThrXLatched_s16):\n",
    "    # Convert continuous parameters to their appropriate format if necessary\n",
    "    params = {\n",
    "        'KLOPFALGO_HfaLatchedCounterThr_u8': int(KLOPFALGO_HfaLatchedCounterThr_u8),\n",
    "        'KLOPFALGO_VelLatchedCounterThr_u8': int(KLOPFALGO_VelLatchedCounterThr_u8),\n",
    "        'KLOPFALGO_VelVeryHighCounterThr_u8': int(KLOPFALGO_VelVeryHighCounterThr_u8),\n",
    "        'KLOPFALGO_HfaThrZLatched_s16': int(KLOPFALGO_HfaThrZLatched_s16),\n",
    "        'KLOPFALGO_VelThrZLatched_s32': int(KLOPFALGO_VelThrZLatched_s32),\n",
    "        'KLOPFALGO_WinkelThrXLatched_s16': int(KLOPFALGO_WinkelThrXLatched_s16)\n",
    "    }\n",
    "    \n",
    "    f1_scores = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, test_index in kf.split(all_sequences):\n",
    "        train, test = [all_sequences[i] for i in train_index], [all_sequences[i] for i in test_index]\n",
    "        predictions = [mimic_knock_detection(sequence, params) for sequence, _ in test]\n",
    "        true_labels = [label for _, label in test]\n",
    "        f1 = f1_score(true_labels, predictions)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Return the average F1 score across folds\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "\n",
    "# Define the parameter bounds\n",
    "pbounds = {\n",
    "    'KLOPFALGO_HfaLatchedCounterThr_u8': (10, 25),\n",
    "    'KLOPFALGO_VelLatchedCounterThr_u8': (10, 40),\n",
    "    'KLOPFALGO_VelVeryHighCounterThr_u8': (3, 8),\n",
    "    'KLOPFALGO_HfaThrZLatched_s16': (6000, 10000),\n",
    "    'KLOPFALGO_VelThrZLatched_s32': (6000, 10000),\n",
    "    'KLOPFALGO_WinkelThrXLatched_s16': (4, 12)\n",
    "\n",
    "}\n",
    "\n",
    "# Instantiate BayesianOptimization object\n",
    "optimizer = BayesianOptimization(\n",
    "    f=knock_detection_cv,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Set up the logger\n",
    "logger = JSONLogger(path=\"./bayes_opt_logs.json\")\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)\n",
    "\n",
    "# Use the expected improvement acquisition function to handle exploration-exploitation trade-off\n",
    "optimizer.maximize(init_points=10, n_iter=60)\n",
    "\n",
    "# Output the best parameters and the corresponding score\n",
    "print(\"Best F1 Score:\", optimizer.max['target'])\n",
    "print(\"Best Parameters:\", optimizer.max['params'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
