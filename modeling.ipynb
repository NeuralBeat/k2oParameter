{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT DEPENDENCIES AND LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, label):\n",
    "    \"\"\"\n",
    "    Process all files in the given folder and compile data into a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path: Path to the folder containing the files.\n",
    "    - label: The label to assign to all data from this folder (e.g., 1 for valid, 0 for invalid).\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame containing all processed data from the files.\n",
    "    \"\"\"\n",
    "    all_data = []  # List to hold data from all files\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Ensure we're only processing .csv files\n",
    "        if os.path.isfile(file_path) and file_path.endswith('.csv'):\n",
    "            # Read the file\n",
    "            data = pd.read_csv(file_path)\n",
    "            \n",
    "            # Filter rows for xBuffer, yBuffer, zBuffer and reset index\n",
    "            x_data = data[data['Expression'] == 'xBuffer'].reset_index(drop=True)\n",
    "            y_data = data[data['Expression'] == 'yBuffer'].reset_index(drop=True)\n",
    "            z_data = data[data['Expression'] == 'zBuffer'].reset_index(drop=True)\n",
    "            \n",
    "            # Ensure data is aligned\n",
    "            min_length = min(len(x_data), len(y_data), len(z_data))\n",
    "            structured_df = pd.DataFrame({\n",
    "                'x': x_data['Value'].head(min_length),\n",
    "                'y': y_data['Value'].head(min_length),\n",
    "                'z': z_data['Value'].head(min_length),\n",
    "                'label': label\n",
    "            })\n",
    "            \n",
    "            # Append to the list\n",
    "            all_data.append(structured_df)\n",
    "    \n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Expression</th>\n",
       "      <th>Value</th>\n",
       "      <th>Location</th>\n",
       "      <th>Refresh</th>\n",
       "      <th>Access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>extractionBuffer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x20005EDC</td>\n",
       "      <td>Off</td>\n",
       "      <td>private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x20005EDC</td>\n",
       "      <td>Off</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>xBuffer</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0x20005EDC</td>\n",
       "      <td>Off</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>yBuffer</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0x20005EDE</td>\n",
       "      <td>Off</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>zBuffer</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0x20005EE0</td>\n",
       "      <td>Off</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level        Expression  Value    Location Refresh   Access\n",
       "0      0  extractionBuffer    NaN  0x20005EDC     Off  private\n",
       "1      1               [0]    NaN  0x20005EDC     Off   public\n",
       "2      2           xBuffer    9.0  0x20005EDC     Off   public\n",
       "3      2           yBuffer  116.0  0x20005EDE     Off   public\n",
       "4      2           zBuffer   54.0  0x20005EE0     Off   public"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the valid knock data\n",
    "valid_data_path = 'data/valid/valid1.csv'\n",
    "valid_data = pd.read_csv(valid_data_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x      y     z  label\n",
       "0    9.0  116.0  54.0      1\n",
       "1    2.0  -20.0  99.0      1\n",
       "2  100.0  111.0 -22.0      1\n",
       "3   33.0   76.0  34.0      1\n",
       "4   15.0  -25.0 -24.0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extract only the rows that contain acceleration values and reset index to avoid grouping issues\n",
    "x_data = valid_data[valid_data['Expression'] == 'xBuffer'].reset_index(drop=True)\n",
    "y_data = valid_data[valid_data['Expression'] == 'yBuffer'].reset_index(drop=True)\n",
    "z_data = valid_data[valid_data['Expression'] == 'zBuffer'].reset_index(drop=True)\n",
    "\n",
    "# Ensure we only take as many rows as the shortest among x, y, z to keep data aligned\n",
    "min_length = min(len(x_data), len(y_data), len(z_data))\n",
    "\n",
    "# Reconstruct the DataFrame using the aligned data\n",
    "structured_df_aligned = pd.DataFrame({\n",
    "    'x': x_data['Value'].head(min_length),\n",
    "    'y': y_data['Value'].head(min_length),\n",
    "    'z': z_data['Value'].head(min_length),\n",
    "    'label': 1  # Label for valid knock\n",
    "})\n",
    "\n",
    "structured_df_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_sequences(df, label):\n",
    "    \"\"\"\n",
    "    Structures the DataFrame such that each 90-row sequence (representing 30 time points of x, y, z data)\n",
    "    is treated as a single observation.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the sequences.\n",
    "    - label: The label for these sequences (1 for valid, 0 for invalid).\n",
    "    \n",
    "    Returns:\n",
    "    - A list of tuples, where each tuple is (sequence, label), and\n",
    "      each sequence is a (90, ) shape array if flattening or a (30, 3) array if keeping x, y, z separate.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    num_sequences = len(df) // 90  # Assuming each sequence is exactly 90 rows\n",
    "    \n",
    "    for i in range(num_sequences):\n",
    "        start_idx = i * 90\n",
    "        sequence = df.iloc[start_idx:start_idx + 90][['x', 'y', 'z']].values.flatten()  # Flattened sequence\n",
    "        # Alternatively, keep as a (30, 3) array for models that can handle sequence data\n",
    "        # sequence = df.iloc[start_idx:start_idx + 90][['x', 'y', 'z']].values.reshape((30, 3))\n",
    "        sequences.append((sequence, label))\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_valid = 'data/valid'  \n",
    "folder_path_invalid = 'data/invalid'  \n",
    "valid_data = process_folder(folder_path_valid, label=1)\n",
    "invalid_data = process_folder(folder_path_invalid, label=0)\n",
    "\n",
    "# Assuming valid_data and invalid_data are already loaded and structured with one file per sequence\n",
    "valid_sequences = structure_sequences(valid_data, 1)\n",
    "invalid_sequences = structure_sequences(invalid_data, 0)\n",
    "\n",
    "all_sequences = valid_sequences + invalid_sequences\n",
    "random.shuffle(all_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels for model training\n",
    "X = np.array([seq[0] for seq in all_sequences])\n",
    "y = np.array([seq[1] for seq in all_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the F1 score between true labels and predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Array-like of true labels.\n",
    "    - y_pred: Array-like of predicted labels.\n",
    "    \n",
    "    Returns:\n",
    "    - f1: The F1 score.\n",
    "    \"\"\"\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'KLOPFALGO_EnableThr_s16': [2800, 3000, 3200, 3400, 3600, 3800, 4000], \n",
    "    'KLOPFALGO_HfaLatchedCounterThr_u8': [10, 15, 20, 25, 30],\n",
    "    'KLOPFALGO_VelLatchedCounterThr_u8': [10, 15, 20, 25],\n",
    "    'KLOPFALGO_HfaVeryHighCounterThr_u8': [3, 5, 7],\n",
    "    'KLOPFALGO_VelVeryHighCounterThr_u8': [3,5,7],\n",
    "    'KLOPFALGO_HfaThrZLatched_s16': [7500, 8500, 9500], \n",
    "    'KLOPFALGO_VelThrZLatched_s32': [8000, 9000 ,10000],\n",
    "    'KLOPFALGO_WinkelThrXLatched_s16': [6,8,10], \n",
    "    'KLOPFALGO_WinkelThrYLatched_s16': [5000, 6000, 7000], \n",
    "    'KLOPFALGO_WinkelThrZLatched_s16': [2900, 3200, 3500, 3800]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_parameters(params, X_train, y_train, X_val, y_val):\n",
    "    # This function should implement the following:\n",
    "    # 1. Run the knock detection algorithm with the given params on X_train.\n",
    "    # 2. Predict knock events on X_val.\n",
    "    # 3. Calculate and return the F1 score comparing predictions to y_val.\n",
    "    # For now, we'll simulate this with a placeholder value.\n",
    "    return simulated_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for values in itertools.product(*parameter_grid.values()):\n",
    "    params = dict(zip(parameter_grid.keys(), values))\n",
    "    \n",
    "    # Simulate the evaluation of these parameters\n",
    "    f1_score = evaluate_parameters(params, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    if f1_score > best_score:\n",
    "        best_score = f1_score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1 Score:\", best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
